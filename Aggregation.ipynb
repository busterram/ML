{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNsrB7gnblL4ch9ddp3mJHB"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":10,"metadata":{"id":"PpWCTJRW42fO","executionInfo":{"status":"ok","timestamp":1720150623272,"user_tz":240,"elapsed":210,"user":{"displayName":"Ram P","userId":"14475938172763703625"}}},"outputs":[],"source":["import pandas as pd\n","import json\n","from collections import Counter\n","\n","# Read the CSV file\n","df = pd.read_csv('fcsample - Action_Dataset.csv')\n","\n","# 1. Top 5 1st level actions\n","first_level_actions = df[(df['level'] == 1) & (df['action_level'] == 1)]['action'].value_counts().nlargest(5).to_dict()\n","\n"]},{"cell_type":"code","source":["# Print 1st level actions\n","print(\"Top 5 First-Level Actions:\\n\", first_level_actions)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b2XYrk1F5H01","executionInfo":{"status":"ok","timestamp":1720150625389,"user_tz":240,"elapsed":210,"user":{"displayName":"Ram P","userId":"14475938172763703625"}},"outputId":"cbe02e47-02f7-4b10-fdd3-6e8012ecae4c"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Top 5 First-Level Actions:\n"," {'a12': 7, 'a13': 5, 'a14': 4, 'a11': 2, 'a15': 1}\n"]}]},{"cell_type":"code","source":["# 2. Top 2 2nd level actions for each 1st level action\n","second_level_actions = {}\n","for index, row in df.iterrows():\n","    if row['level'] == 1 and row['action_level'] == 1:\n","        first_action = row['action']\n","        if index + 1 < len(df):\n","            next_row = df.iloc[index + 1]\n","            if next_row['level'] == 0 and next_row['action_level'] == 2:\n","                if first_action not in second_level_actions:\n","                    second_level_actions[first_action] = Counter()\n","                second_level_actions[first_action][next_row['action']] += 1\n","\n","for action in second_level_actions:\n","    second_level_actions[action] = dict(second_level_actions[action].most_common(5))\n","\n"],"metadata":{"id":"-ay62zcv5ATR","executionInfo":{"status":"ok","timestamp":1720150653502,"user_tz":240,"elapsed":277,"user":{"displayName":"Ram P","userId":"14475938172763703625"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["# Print 1st level actions\n","print(\"Top 3 Second-Level Actions:\\n\", second_level_actions)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9Vi-uOJH5lKz","executionInfo":{"status":"ok","timestamp":1720150655937,"user_tz":240,"elapsed":243,"user":{"displayName":"Ram P","userId":"14475938172763703625"}},"outputId":"685103e4-18b7-48f9-bb6c-2b7e24d864ef"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Top 3 Second-Level Actions:\n"," {'a14': {'a11': 2, 'a13': 2}, 'a11': {'a13': 1, 'a14': 1}, 'a13': {'a14': 2, 'a12': 1, 'a15': 1, 'a11': 1}, 'a12': {'a15': 3, 'a13': 2, 'a14': 1, 'a11': 1}, 'a15': {'a11': 1}}\n"]}]},{"cell_type":"code","source":["# 3. Top 2 3rd level actions for each 1st/2nd level action combination\n","third_level_actions = {}\n","for index, row in df.iterrows():\n","    if row['level'] == 1 and row['action_level'] == 1:\n","        first_action = row['action']\n","        if index + 1 < len(df) and index + 2 < len(df):\n","            second_row = df.iloc[index + 1]\n","            third_row = df.iloc[index + 2]\n","            if (second_row['level'] == 0 and second_row['action_level'] == 2 and\n","                third_row['level'] == 0 and third_row['action_level'] == 3):\n","                key = (first_action, second_row['action'])\n","                if key not in third_level_actions:\n","                    third_level_actions[key] = Counter()\n","                third_level_actions[key][third_row['action']] += 1\n","\n","for key in third_level_actions:\n","    third_level_actions[key] = dict(third_level_actions[key].most_common(5))\n","\n"],"metadata":{"id":"5QylIUSh5BtZ","executionInfo":{"status":"ok","timestamp":1720149713237,"user_tz":240,"elapsed":303,"user":{"displayName":"Ram P","userId":"14475938172763703625"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"fIb_QgN787cH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Print 1st level actions\n","print(\"Top 3 Third-Level Actions:\\n\", third_level_actions)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uw5NVgs46a5n","executionInfo":{"status":"ok","timestamp":1720149726827,"user_tz":240,"elapsed":179,"user":{"displayName":"Ram P","userId":"14475938172763703625"}},"outputId":"7502872c-c4b6-4734-8166-dc339a5f1014"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Top 3 Third-Level Actions:\n"," {('a14', 'a11'): {'a12': 2}, ('a14', 'a13'): {'a15': 2}, ('a11', 'a13'): {'a15': 1}, ('a13', 'a12'): {'a11': 1}, ('a12', 'a13'): {'a11': 2}, ('a12', 'a15'): {'a14': 2, 'a11': 1}, ('a11', 'a14'): {'a13': 1}, ('a13', 'a14'): {'a11': 2}, ('a12', 'a14'): {'a15': 1}, ('a13', 'a15'): {'a14': 1}, ('a13', 'a11'): {'a12': 1}, ('a15', 'a11'): {'a14': 1}, ('a12', 'a11'): {'a14': 1}}\n"]}]},{"cell_type":"code","source":["# Prepare the JSON output\n","result = {\n","    \"top_5_first_level_actions\": first_level_actions,\n","    \"top_2_second_level_actions\": second_level_actions,\n","    \"top_2_third_level_actions\": {f\"{k[0]}-{k[1]}\": v for k, v in third_level_actions.items()}\n","}\n","\n","# Convert to JSON\n","json_output = json.dumps(result, indent=2)\n","\n","# Print or save the JSON output\n","print(json_output)\n","\n","# Optionally, save to a file\n","# with open('action_analysis.json', 'w') as f:\n","#     json.dump(result, f, indent=2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5gEF88sx5D4-","executionInfo":{"status":"ok","timestamp":1720149742945,"user_tz":240,"elapsed":382,"user":{"displayName":"Ram P","userId":"14475938172763703625"}},"outputId":"0e85bd11-fdac-4043-8a9a-8471370d837e"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["{\n","  \"top_5_first_level_actions\": {\n","    \"a12\": 7,\n","    \"a13\": 5,\n","    \"a14\": 4,\n","    \"a11\": 2,\n","    \"a15\": 1\n","  },\n","  \"top_2_second_level_actions\": {\n","    \"a14\": {\n","      \"a11\": 2,\n","      \"a13\": 2\n","    },\n","    \"a11\": {\n","      \"a13\": 1,\n","      \"a14\": 1\n","    },\n","    \"a13\": {\n","      \"a14\": 2,\n","      \"a12\": 1\n","    },\n","    \"a12\": {\n","      \"a15\": 3,\n","      \"a13\": 2\n","    },\n","    \"a15\": {\n","      \"a11\": 1\n","    }\n","  },\n","  \"top_2_third_level_actions\": {\n","    \"a14-a11\": {\n","      \"a12\": 2\n","    },\n","    \"a14-a13\": {\n","      \"a15\": 2\n","    },\n","    \"a11-a13\": {\n","      \"a15\": 1\n","    },\n","    \"a13-a12\": {\n","      \"a11\": 1\n","    },\n","    \"a12-a13\": {\n","      \"a11\": 2\n","    },\n","    \"a12-a15\": {\n","      \"a14\": 2,\n","      \"a11\": 1\n","    },\n","    \"a11-a14\": {\n","      \"a13\": 1\n","    },\n","    \"a13-a14\": {\n","      \"a11\": 2\n","    },\n","    \"a12-a14\": {\n","      \"a15\": 1\n","    },\n","    \"a13-a15\": {\n","      \"a14\": 1\n","    },\n","    \"a13-a11\": {\n","      \"a12\": 1\n","    },\n","    \"a15-a11\": {\n","      \"a14\": 1\n","    },\n","    \"a12-a11\": {\n","      \"a14\": 1\n","    }\n","  }\n","}\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import json\n","from collections import Counter\n","\n","# Read the CSV file\n","df = pd.read_csv('fcsample - Action_Dataset.csv')\n","\n","# 1. Top 5 1st level actions\n","first_level_actions = df[(df['level'] == 1) & (df['action_level'] == 1)]['action'].value_counts().nlargest(5).to_dict()\n","\n","# Print 1st level actions\n","print(\"Top 5 1st-Level Actions:\\n\", first_level_actions)\n","\n","# 2. Top 5 2nd level actions\n","second_level_actions = Counter()\n","for i in range(1, len(df)):\n","    current_row = df.iloc[i]\n","    previous_row = df.iloc[i-1]\n","    if (current_row['level'] == 0 and current_row['action_level'] == 2 and\n","        previous_row['level'] == 1 and previous_row['action_level'] == 1):\n","        second_level_actions[current_row['action']] += 1\n","\n","second_level_actions = dict(second_level_actions.most_common(5))\n","\n","# Print 2nd level actions\n","print(\"Top 5 2nd-Level Actions:\\n\", second_level_actions)\n","\n","# 3. Top 5 3rd level actions\n","third_level_actions = Counter()\n","for i in range(1, len(df)):\n","    current_row = df.iloc[i]\n","    previous_row = df.iloc[i-1]\n","    if (current_row['level'] == 0 and current_row['action_level'] == 3 and\n","        previous_row['level'] == 0 and previous_row['action_level'] == 2):\n","        third_level_actions[current_row['action']] += 1\n","\n","third_level_actions = dict(third_level_actions.most_common(5))\n","\n","# Print 3rd level actions\n","print(\"Top 5 3rd-Level Actions:\\n\", third_level_actions)\n","\n","# Prepare the JSON output\n","result = {\n","    \"top_5_first_level_actions\": first_level_actions,\n","    \"top_5_second_level_actions\": second_level_actions,\n","    \"top_5_third_level_actions\": third_level_actions\n","}\n","\n","# Convert to JSON\n","json_output = json.dumps(result, indent=2)\n","\n","# Print the JSON output\n","print(json_output)\n","\n","# Optionally, save to a file\n","# with open('action_analysis.json', 'w') as f:\n","#     json.dump(result, f, indent=2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5TZBz4Mi9IWc","executionInfo":{"status":"ok","timestamp":1720150502039,"user_tz":240,"elapsed":253,"user":{"displayName":"Ram P","userId":"14475938172763703625"}},"outputId":"7d592b1c-c0eb-45cf-8c86-4404c1168faa"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Top 5 1st-Level Actions:\n"," {'a12': 7, 'a13': 5, 'a14': 4, 'a11': 2, 'a15': 1}\n","Top 5 2nd-Level Actions:\n"," {'a11': 5, 'a13': 5, 'a15': 4, 'a14': 4, 'a12': 1}\n","Top 5 3rd-Level Actions:\n"," {'a14': 6, 'a11': 6, 'a15': 4, 'a12': 3, 'a13': 1}\n","{\n","  \"top_5_first_level_actions\": {\n","    \"a12\": 7,\n","    \"a13\": 5,\n","    \"a14\": 4,\n","    \"a11\": 2,\n","    \"a15\": 1\n","  },\n","  \"top_5_second_level_actions\": {\n","    \"a11\": 5,\n","    \"a13\": 5,\n","    \"a15\": 4,\n","    \"a14\": 4,\n","    \"a12\": 1\n","  },\n","  \"top_5_third_level_actions\": {\n","    \"a14\": 6,\n","    \"a11\": 6,\n","    \"a15\": 4,\n","    \"a12\": 3,\n","    \"a13\": 1\n","  }\n","}\n"]}]},{"cell_type":"code","source":["# This is the good working version from Claude\n","import pandas as pd\n","import json\n","from collections import Counter, defaultdict\n","\n","# Read the CSV file\n","df = pd.read_csv('fcsample - Action_Dataset.csv')\n","\n","# 1. Top 5 1st level actions\n","first_level_actions = df[(df['level'] == 1) & (df['action_level'] == 1)]['action'].value_counts().nlargest(5).to_dict()\n","\n","# 2. Top 5 2nd level actions for each 1st level action\n","second_level_actions = defaultdict(Counter)\n","for i in range(len(df) - 1):\n","    current_row = df.iloc[i]\n","    next_row = df.iloc[i + 1]\n","    if (current_row['level'] == 1 and current_row['action_level'] == 1 and\n","        next_row['level'] == 0 and next_row['action_level'] == 2):\n","        second_level_actions[current_row['action']][next_row['action']] += 1\n","\n","second_level_top5 = {action: dict(counter.most_common(5)) for action, counter in second_level_actions.items()}\n","\n","# 3. Top 5 3rd level actions for each 1st/2nd level action combination\n","third_level_actions = defaultdict(Counter)\n","for i in range(len(df) - 2):\n","    first_row = df.iloc[i]\n","    second_row = df.iloc[i + 1]\n","    third_row = df.iloc[i + 2]\n","    if (first_row['level'] == 1 and first_row['action_level'] == 1 and\n","        second_row['level'] == 0 and second_row['action_level'] == 2 and\n","        third_row['level'] == 0 and third_row['action_level'] == 3):\n","        key = (first_row['action'], second_row['action'])\n","        third_level_actions[key][third_row['action']] += 1\n","\n","third_level_top5 = {f\"{k[0]}-{k[1]}\": dict(v.most_common(5)) for k, v in third_level_actions.items()}\n","\n","# Prepare the JSON output\n","result = {\n","    \"top_5_first_level_actions\": first_level_actions,\n","    \"top_5_second_level_actions_per_first\": second_level_top5,\n","    \"top_5_third_level_actions_per_combo\": third_level_top5\n","}\n","\n","# Convert to JSON\n","json_output = json.dumps(result, indent=2)\n","\n","# Print the JSON output\n","print(json_output)\n","\n","# Optionally, save to a file\n","# with open('action_analysis.json', 'w') as f:\n","#     json.dump(result, f, indent=2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SczLPm8P--h8","executionInfo":{"status":"ok","timestamp":1720150918893,"user_tz":240,"elapsed":244,"user":{"displayName":"Ram P","userId":"14475938172763703625"}},"outputId":"2b18743b-eac4-4d17-e4cb-26706d613cd0"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["{\n","  \"top_5_first_level_actions\": {\n","    \"a12\": 7,\n","    \"a13\": 5,\n","    \"a14\": 4,\n","    \"a11\": 2,\n","    \"a15\": 1\n","  },\n","  \"top_5_second_level_actions_per_first\": {\n","    \"a14\": {\n","      \"a11\": 2,\n","      \"a13\": 2\n","    },\n","    \"a11\": {\n","      \"a13\": 1,\n","      \"a14\": 1\n","    },\n","    \"a13\": {\n","      \"a14\": 2,\n","      \"a12\": 1,\n","      \"a15\": 1,\n","      \"a11\": 1\n","    },\n","    \"a12\": {\n","      \"a15\": 3,\n","      \"a13\": 2,\n","      \"a14\": 1,\n","      \"a11\": 1\n","    },\n","    \"a15\": {\n","      \"a11\": 1\n","    }\n","  },\n","  \"top_5_third_level_actions_per_combo\": {\n","    \"a14-a11\": {\n","      \"a12\": 2\n","    },\n","    \"a14-a13\": {\n","      \"a15\": 2\n","    },\n","    \"a11-a13\": {\n","      \"a15\": 1\n","    },\n","    \"a13-a12\": {\n","      \"a11\": 1\n","    },\n","    \"a12-a13\": {\n","      \"a11\": 2\n","    },\n","    \"a12-a15\": {\n","      \"a14\": 2,\n","      \"a11\": 1\n","    },\n","    \"a11-a14\": {\n","      \"a13\": 1\n","    },\n","    \"a13-a14\": {\n","      \"a11\": 2\n","    },\n","    \"a12-a14\": {\n","      \"a15\": 1\n","    },\n","    \"a13-a15\": {\n","      \"a14\": 1\n","    },\n","    \"a13-a11\": {\n","      \"a12\": 1\n","    },\n","    \"a15-a11\": {\n","      \"a14\": 1\n","    },\n","    \"a12-a11\": {\n","      \"a14\": 1\n","    }\n","  }\n","}\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import json\n","from collections import defaultdict\n","\n","# Read the CSV file\n","df = pd.read_csv('fcsample - Action_Dataset.csv')\n","\n","# 1. Top 5 1st level actions\n","first_level_actions = df[(df['level'] == 1) & (df['action_level'] == 1)]['action'].value_counts().nlargest(5).to_dict()\n","\n","# Helper function to get top 5 actions\n","def get_top_5(group):\n","    return group.value_counts().nlargest(5).to_dict()\n","\n","# 2. Top 5 2nd level actions for each 1st level action\n","df['prev_action'] = df['action'].shift()\n","df['prev_level'] = df['level'].shift()\n","df['prev_action_level'] = df['action_level'].shift()\n","\n","second_level_mask = (\n","    (df['level'] == 0) &\n","    (df['action_level'] == 2) &\n","    (df['prev_level'] == 1) &\n","    (df['prev_action_level'] == 1)\n",")\n","\n","second_level_actions = df[second_level_mask].groupby('prev_action')['action'].apply(get_top_5).to_dict()\n","\n","# 3. Top 5 3rd level actions for each 1st/2nd level action combination\n","df['prev_prev_action'] = df['action'].shift(2)\n","df['prev_prev_level'] = df['level'].shift(2)\n","df['prev_prev_action_level'] = df['action_level'].shift(2)\n","\n","third_level_mask = (\n","    (df['level'] == 0) &\n","    (df['action_level'] == 3) &\n","    (df['prev_level'] == 0) &\n","    (df['prev_action_level'] == 2) &\n","    (df['prev_prev_level'] == 1) &\n","    (df['prev_prev_action_level'] == 1)\n",")\n","\n","third_level_actions = df[third_level_mask].groupby(['prev_prev_action', 'prev_action'])['action'].apply(get_top_5)\n","third_level_actions = {f\"{k[0]}-{k[1]}\": v for k, v in third_level_actions.to_dict().items()}\n","\n","# Prepare the JSON output\n","result = {\n","    \"top_5_first_level_actions\": first_level_actions,\n","    \"top_5_second_level_actions_per_first\": second_level_actions,\n","    \"top_5_third_level_actions_per_combo\": third_level_actions\n","}\n","\n","# Convert any non-string keys to strings\n","def stringify_keys(d):\n","    return {str(key): value if not isinstance(value, dict) else stringify_keys(value)\n","            for key, value in d.items()}\n","\n","result = stringify_keys(result)\n","\n","# Convert to JSON\n","json_output = json.dumps(result, indent=2)\n","\n","# Print the JSON output\n","print(json_output)\n","\n","# Optionally, save to a file\n","# with open('action_analysis.json', 'w') as f:\n","#     json.dump(result, f, indent=2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bCiTB5SSF7zU","executionInfo":{"status":"ok","timestamp":1720152739494,"user_tz":240,"elapsed":197,"user":{"displayName":"Ram P","userId":"14475938172763703625"}},"outputId":"c065270d-5c6c-4df0-e319-e84e95dacd17"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["{\n","  \"top_5_first_level_actions\": {\n","    \"a12\": 7,\n","    \"a13\": 5,\n","    \"a14\": 4,\n","    \"a11\": 2,\n","    \"a15\": 1\n","  },\n","  \"top_5_second_level_actions_per_first\": {\n","    \"('a11', 'a13')\": 1.0,\n","    \"('a11', 'a14')\": 1.0,\n","    \"('a11', 'a15')\": NaN,\n","    \"('a11', 'a11')\": NaN,\n","    \"('a11', 'a12')\": NaN,\n","    \"('a12', 'a13')\": 2.0,\n","    \"('a12', 'a14')\": 1.0,\n","    \"('a12', 'a15')\": 3.0,\n","    \"('a12', 'a11')\": 1.0,\n","    \"('a12', 'a12')\": NaN,\n","    \"('a13', 'a13')\": NaN,\n","    \"('a13', 'a14')\": 2.0,\n","    \"('a13', 'a15')\": 1.0,\n","    \"('a13', 'a11')\": 1.0,\n","    \"('a13', 'a12')\": 1.0,\n","    \"('a14', 'a13')\": 2.0,\n","    \"('a14', 'a14')\": NaN,\n","    \"('a14', 'a15')\": NaN,\n","    \"('a14', 'a11')\": 2.0,\n","    \"('a14', 'a12')\": NaN,\n","    \"('a15', 'a13')\": NaN,\n","    \"('a15', 'a14')\": NaN,\n","    \"('a15', 'a15')\": NaN,\n","    \"('a15', 'a11')\": 1.0,\n","    \"('a15', 'a12')\": NaN\n","  },\n","  \"top_5_third_level_actions_per_combo\": {\n","    \"a11-a13\": NaN,\n","    \"a11-a14\": NaN,\n","    \"a12-a11\": NaN,\n","    \"a12-a13\": NaN,\n","    \"a12-a14\": NaN,\n","    \"a12-a15\": NaN,\n","    \"a13-a11\": 1.0,\n","    \"a13-a12\": NaN,\n","    \"a13-a14\": NaN,\n","    \"a13-a15\": NaN,\n","    \"a14-a11\": 2.0,\n","    \"a14-a13\": NaN,\n","    \"a15-a11\": NaN\n","  }\n","}\n"]}]},{"cell_type":"code","source":["# Deleted NAGH\n","import pandas as pd\n","import json\n","import numpy as np\n","\n","# Read the CSV file\n","df = pd.read_csv('fcsample - Action_Dataset.csv')\n","\n","# Helper function to get top 5 actions, excluding NaN values\n","def get_top_5(group):\n","    return group.value_counts().nlargest(5).to_dict()\n","\n","# 1. Top 5 1st level actions\n","first_level_actions = df[(df['level'] == 1) & (df['action_level'] == 1)]['action'].value_counts().nlargest(5).to_dict()\n","\n","# 2. Top 5 2nd level actions for each 1st level action\n","df['prev_action'] = df['action'].shift()\n","df['prev_level'] = df['level'].shift()\n","df['prev_action_level'] = df['action_level'].shift()\n","\n","second_level_mask = (\n","    (df['level'] == 0) &\n","    (df['action_level'] == 2) &\n","    (df['prev_level'] == 1) &\n","    (df['prev_action_level'] == 1)\n",")\n","\n","second_level_actions = df[second_level_mask].groupby('prev_action')['action'].apply(get_top_5).to_dict()\n","\n","# 3. Top 5 3rd level actions for each 1st/2nd level action combination\n","df['prev_prev_action'] = df['action'].shift(2)\n","df['prev_prev_level'] = df['level'].shift(2)\n","df['prev_prev_action_level'] = df['action_level'].shift(2)\n","\n","third_level_mask = (\n","    (df['level'] == 0) &\n","    (df['action_level'] == 3) &\n","    (df['prev_level'] == 0) &\n","    (df['prev_action_level'] == 2) &\n","    (df['prev_prev_level'] == 1) &\n","    (df['prev_prev_action_level'] == 1)\n",")\n","\n","third_level_actions = df[third_level_mask].groupby(['prev_prev_action', 'prev_action'])['action'].apply(get_top_5)\n","third_level_actions = {f\"{k[0]}-{k[1]}\": v for k, v in third_level_actions.to_dict().items()}\n","\n","# Prepare the JSON output\n","result = {\n","    \"top_5_first_level_actions\": first_level_actions,\n","    \"top_5_second_level_actions_per_first\": second_level_actions,\n","    \"top_5_third_level_actions_per_combo\": third_level_actions\n","}\n","\n","# Function to remove NaN values, convert to int, and stringify keys\n","def clean_dict(d):\n","    if isinstance(d, dict):\n","        return {str(k): clean_dict(v) for k, v in d.items() if not (isinstance(v, float) and np.isnan(v))}\n","    elif isinstance(d, float) and not np.isnan(d):\n","        return int(d)\n","    else:\n","        return d\n","\n","# Clean the result dictionary\n","result = clean_dict(result)\n","\n","# Convert to JSON\n","json_output = json.dumps(result, indent=2)\n","\n","# Print the JSON output\n","print(json_output)\n","\n","# Optionally, save to a file\n","# with open('action_analysis.json', 'w') as f:\n","#     json.dump(result, f, indent=2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-dPK9CzjHMyl","executionInfo":{"status":"ok","timestamp":1720153080145,"user_tz":240,"elapsed":223,"user":{"displayName":"Ram P","userId":"14475938172763703625"}},"outputId":"5d0893b2-cc0e-4b8b-c6d2-abe36e343aa0"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["{\n","  \"top_5_first_level_actions\": {\n","    \"a12\": 7,\n","    \"a13\": 5,\n","    \"a14\": 4,\n","    \"a11\": 2,\n","    \"a15\": 1\n","  },\n","  \"top_5_second_level_actions_per_first\": {\n","    \"('a11', 'a13')\": 1,\n","    \"('a11', 'a14')\": 1,\n","    \"('a12', 'a13')\": 2,\n","    \"('a12', 'a14')\": 1,\n","    \"('a12', 'a15')\": 3,\n","    \"('a12', 'a11')\": 1,\n","    \"('a13', 'a14')\": 2,\n","    \"('a13', 'a15')\": 1,\n","    \"('a13', 'a11')\": 1,\n","    \"('a13', 'a12')\": 1,\n","    \"('a14', 'a13')\": 2,\n","    \"('a14', 'a11')\": 2,\n","    \"('a15', 'a11')\": 1\n","  },\n","  \"top_5_third_level_actions_per_combo\": {\n","    \"a13-a11\": 1,\n","    \"a14-a11\": 2\n","  }\n","}\n"]}]},{"cell_type":"code","source":["# Unsorted one\n","import pandas as pd\n","import json\n","import numpy as np\n","\n","# Read the CSV file\n","df = pd.read_csv('fcsample - Action_Dataset.csv')\n","\n","# Helper function to get top 5 actions, excluding NaN values\n","def get_top_5(group):\n","    counts = group.value_counts().nlargest(5)\n","    return {str(index): int(value) for index, value in counts.items()}\n","\n","# 1. Top 5 1st level actions\n","first_level_actions = df[(df['level'] == 1) & (df['action_level'] == 1)]['action'].value_counts().nlargest(5).to_dict()\n","\n","# 2. Top 5 2nd level actions for each 1st level action\n","df['prev_action'] = df['action'].shift()\n","df['prev_level'] = df['level'].shift()\n","df['prev_action_level'] = df['action_level'].shift()\n","\n","second_level_mask = (\n","    (df['level'] == 0) &\n","    (df['action_level'] == 2) &\n","    (df['prev_level'] == 1) &\n","    (df['prev_action_level'] == 1)\n",")\n","\n","second_level_df = df[second_level_mask].groupby(['prev_action', 'action']).size().reset_index(name='count')\n","second_level_actions = {}\n","for first_level in second_level_df['prev_action'].unique():\n","    top_5 = second_level_df[second_level_df['prev_action'] == first_level].nlargest(5, 'count')\n","    for _, row in top_5.iterrows():\n","        key = f\"{first_level}-{row['action']}\"\n","        second_level_actions[key] = int(row['count'])\n","\n","# 3. Top 5 3rd level actions for each 1st/2nd level action combination\n","df['prev_prev_action'] = df['action'].shift(2)\n","df['prev_prev_level'] = df['level'].shift(2)\n","df['prev_prev_action_level'] = df['action_level'].shift(2)\n","\n","third_level_mask = (\n","    (df['level'] == 0) &\n","    (df['action_level'] == 3) &\n","    (df['prev_level'] == 0) &\n","    (df['prev_action_level'] == 2) &\n","    (df['prev_prev_level'] == 1) &\n","    (df['prev_prev_action_level'] == 1)\n",")\n","\n","third_level_df = df[third_level_mask].groupby(['prev_prev_action', 'prev_action', 'action']).size().reset_index(name='count')\n","third_level_actions = {}\n","for first_level in third_level_df['prev_prev_action'].unique():\n","    for second_level in third_level_df[third_level_df['prev_prev_action'] == first_level]['prev_action'].unique():\n","        top_5 = third_level_df[(third_level_df['prev_prev_action'] == first_level) &\n","                               (third_level_df['prev_action'] == second_level)].nlargest(5, 'count')\n","        for _, row in top_5.iterrows():\n","            key = f\"{first_level}-{second_level}-{row['action']}\"\n","            third_level_actions[key] = int(row['count'])\n","\n","# Prepare the JSON output\n","result = {\n","    \"top_5_first_level_actions\": first_level_actions,\n","    \"top_5_second_level_actions_per_first\": second_level_actions,\n","    \"top_5_third_level_actions_per_combo\": third_level_actions\n","}\n","\n","# Function to remove NaN values and convert to int\n","def clean_dict(d):\n","    if isinstance(d, dict):\n","        return {str(k): clean_dict(v) for k, v in d.items() if not (isinstance(v, float) and np.isnan(v))}\n","    elif isinstance(d, float) and not np.isnan(d):\n","        return int(d)\n","    else:\n","        return d\n","\n","# Clean the result dictionary\n","result = clean_dict(result)\n","\n","# Convert to JSON\n","json_output = json.dumps(result, indent=2)\n","\n","# Print the JSON output\n","print(json_output)\n","\n","# Optionally, save to a file\n","# with open('action_analysis.json', 'w') as f:\n","#     json.dump(result, f, indent=2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9JNH5u1SKEIJ","executionInfo":{"status":"ok","timestamp":1720153822439,"user_tz":240,"elapsed":226,"user":{"displayName":"Ram P","userId":"14475938172763703625"}},"outputId":"62aaee50-47bd-43f0-e3dd-8e4b65a2ae06"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["{\n","  \"top_5_first_level_actions\": {\n","    \"a12\": 7,\n","    \"a13\": 5,\n","    \"a14\": 4,\n","    \"a11\": 2,\n","    \"a15\": 1\n","  },\n","  \"top_5_second_level_actions_per_first\": {\n","    \"a11-a13\": 1,\n","    \"a11-a14\": 1,\n","    \"a12-a15\": 3,\n","    \"a12-a13\": 2,\n","    \"a12-a11\": 1,\n","    \"a12-a14\": 1,\n","    \"a13-a14\": 2,\n","    \"a13-a11\": 1,\n","    \"a13-a12\": 1,\n","    \"a13-a15\": 1,\n","    \"a14-a11\": 2,\n","    \"a14-a13\": 2,\n","    \"a15-a11\": 1\n","  },\n","  \"top_5_third_level_actions_per_combo\": {\n","    \"a11-a13-a15\": 1,\n","    \"a11-a14-a13\": 1,\n","    \"a12-a11-a14\": 1,\n","    \"a12-a13-a11\": 2,\n","    \"a12-a14-a15\": 1,\n","    \"a12-a15-a14\": 2,\n","    \"a12-a15-a11\": 1,\n","    \"a13-a11-a12\": 1,\n","    \"a13-a12-a11\": 1,\n","    \"a13-a14-a11\": 2,\n","    \"a13-a15-a14\": 1,\n","    \"a14-a11-a12\": 2,\n","    \"a14-a13-a15\": 2,\n","    \"a15-a11-a14\": 1\n","  }\n","}\n"]}]},{"cell_type":"code","source":["# Final one sent to Alok with sorting enabled\n","import pandas as pd\n","import json\n","import numpy as np\n","from collections import OrderedDict\n","\n","# Read the CSV file\n","df = pd.read_csv('fcsample - Action_Dataset.csv')\n","\n","# 1. Top 5 1st level actions\n","first_level_actions = df[(df['level'] == 1) & (df['action_level'] == 1)]['action'].value_counts().nlargest(5).to_dict()\n","first_level_actions = OrderedDict(sorted(first_level_actions.items(), key=lambda x: x[1], reverse=True))\n","\n","# 2. Top 5 2nd level actions for each 1st level action\n","df['prev_action'] = df['action'].shift()\n","df['prev_level'] = df['level'].shift()\n","df['prev_action_level'] = df['action_level'].shift()\n","\n","second_level_mask = (\n","    (df['level'] == 0) &\n","    (df['action_level'] == 2) &\n","    (df['prev_level'] == 1) &\n","    (df['prev_action_level'] == 1)\n",")\n","\n","second_level_df = df[second_level_mask].groupby(['prev_action', 'action']).size().reset_index(name='count')\n","second_level_actions = {}\n","for first_level in second_level_df['prev_action'].unique():\n","    top_5 = second_level_df[second_level_df['prev_action'] == first_level].nlargest(5, 'count')\n","    for _, row in top_5.iterrows():\n","        key = f\"{first_level}-{row['action']}\"\n","        second_level_actions[key] = int(row['count'])\n","second_level_actions = OrderedDict(sorted(second_level_actions.items(), key=lambda x: x[1], reverse=True))\n","\n","# 3. Top 5 3rd level actions for each 1st/2nd level action combination\n","df['prev_prev_action'] = df['action'].shift(2)\n","df['prev_prev_level'] = df['level'].shift(2)\n","df['prev_prev_action_level'] = df['action_level'].shift(2)\n","\n","third_level_mask = (\n","    (df['level'] == 0) &\n","    (df['action_level'] == 3) &\n","    (df['prev_level'] == 0) &\n","    (df['prev_action_level'] == 2) &\n","    (df['prev_prev_level'] == 1) &\n","    (df['prev_prev_action_level'] == 1)\n",")\n","\n","third_level_df = df[third_level_mask].groupby(['prev_prev_action', 'prev_action', 'action']).size().reset_index(name='count')\n","third_level_actions = {}\n","for first_level in third_level_df['prev_prev_action'].unique():\n","    for second_level in third_level_df[third_level_df['prev_prev_action'] == first_level]['prev_action'].unique():\n","        top_5 = third_level_df[(third_level_df['prev_prev_action'] == first_level) &\n","                               (third_level_df['prev_action'] == second_level)].nlargest(5, 'count')\n","        for _, row in top_5.iterrows():\n","            key = f\"{first_level}-{second_level}-{row['action']}\"\n","            third_level_actions[key] = int(row['count'])\n","third_level_actions = OrderedDict(sorted(third_level_actions.items(), key=lambda x: x[1], reverse=True))\n","\n","# Prepare the JSON output\n","result = {\n","    \"top_5_first_level_actions\": first_level_actions,\n","    \"top_5_second_level_actions_per_first\": second_level_actions,\n","    \"top_5_third_level_actions_per_combo\": third_level_actions\n","}\n","\n","# Function to remove NaN values and convert to int\n","def clean_dict(d):\n","    if isinstance(d, dict):\n","        return OrderedDict((str(k), clean_dict(v)) for k, v in d.items() if not (isinstance(v, float) and np.isnan(v)))\n","    elif isinstance(d, float) and not np.isnan(d):\n","        return int(d)\n","    else:\n","        return d\n","\n","# Clean the result dictionary\n","result = clean_dict(result)\n","\n","# Convert to JSON\n","json_output = json.dumps(result, indent=2)\n","\n","# Print the JSON output\n","print(json_output)\n","\n","# Optionally, save to a file\n","# with open('action_analysis.json', 'w') as f:\n","#     json.dump(result, f, indent=2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4Zrp5VxJNgxq","executionInfo":{"status":"ok","timestamp":1720154726623,"user_tz":240,"elapsed":249,"user":{"displayName":"Ram P","userId":"14475938172763703625"}},"outputId":"ad27daf7-a36d-4fde-c918-309813e32faf"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["{\n","  \"top_5_first_level_actions\": {\n","    \"a12\": 7,\n","    \"a13\": 5,\n","    \"a14\": 4,\n","    \"a11\": 2,\n","    \"a15\": 1\n","  },\n","  \"top_5_second_level_actions_per_first\": {\n","    \"a12-a15\": 3,\n","    \"a12-a13\": 2,\n","    \"a13-a14\": 2,\n","    \"a14-a11\": 2,\n","    \"a14-a13\": 2,\n","    \"a11-a13\": 1,\n","    \"a11-a14\": 1,\n","    \"a12-a11\": 1,\n","    \"a12-a14\": 1,\n","    \"a13-a11\": 1,\n","    \"a13-a12\": 1,\n","    \"a13-a15\": 1,\n","    \"a15-a11\": 1\n","  },\n","  \"top_5_third_level_actions_per_combo\": {\n","    \"a12-a13-a11\": 2,\n","    \"a12-a15-a14\": 2,\n","    \"a13-a14-a11\": 2,\n","    \"a14-a11-a12\": 2,\n","    \"a14-a13-a15\": 2,\n","    \"a11-a13-a15\": 1,\n","    \"a11-a14-a13\": 1,\n","    \"a12-a11-a14\": 1,\n","    \"a12-a14-a15\": 1,\n","    \"a12-a15-a11\": 1,\n","    \"a13-a11-a12\": 1,\n","    \"a13-a12-a11\": 1,\n","    \"a13-a15-a14\": 1,\n","    \"a15-a11-a14\": 1\n","  }\n","}\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import json\n","import numpy as np\n","from collections import OrderedDict\n","\n","# Read the CSV file\n","df = pd.read_csv('fcsample - Action_Dataset.csv')\n","\n","# 1. Top 5 1st level actions\n","first_level_actions = df[(df['level'] == 1) & (df['action_level'] == 1)]['action'].value_counts().nlargest(5).to_dict()\n","first_level_actions = OrderedDict(sorted(first_level_actions.items(), key=lambda x: x[1], reverse=True))\n","\n","# 2. Top 5 2nd level actions for each 1st level action\n","df['prev_action'] = df['action'].shift()\n","df['prev_level'] = df['level'].shift()\n","df['prev_action_level'] = df['action_level'].shift()\n","\n","second_level_mask = (\n","    (df['level'] == 0) &\n","    (df['action_level'] == 2) &\n","    (df['prev_level'] == 1) &\n","    (df['prev_action_level'] == 1)\n",")\n","\n","second_level_df = df[second_level_mask].groupby(['prev_action', 'action']).size().reset_index(name='count')\n","second_level_actions = {}\n","for first_level in second_level_df['prev_action'].unique():\n","    top_5 = second_level_df[second_level_df['prev_action'] == first_level].nlargest(5, 'count')\n","    for _, row in top_5.iterrows():\n","        key = f\"{first_level}-{row['action']}\"\n","        second_level_actions[key] = {\n","            'count': int(row['count']),\n","            'level1_count': first_level_actions.get(first_level, 0)\n","        }\n","second_level_actions = OrderedDict(sorted(second_level_actions.items(), key=lambda x: x[1]['count'], reverse=True))\n","\n","# 3. Top 5 3rd level actions for each 1st/2nd level action combination\n","df['prev_prev_action'] = df['action'].shift(2)\n","df['prev_prev_level'] = df['level'].shift(2)\n","df['prev_prev_action_level'] = df['action_level'].shift(2)\n","\n","third_level_mask = (\n","    (df['level'] == 0) &\n","    (df['action_level'] == 3) &\n","    (df['prev_level'] == 0) &\n","    (df['prev_action_level'] == 2) &\n","    (df['prev_prev_level'] == 1) &\n","    (df['prev_prev_action_level'] == 1)\n",")\n","\n","third_level_df = df[third_level_mask].groupby(['prev_prev_action', 'prev_action', 'action']).size().reset_index(name='count')\n","third_level_actions = {}\n","for first_level in third_level_df['prev_prev_action'].unique():\n","    for second_level in third_level_df[third_level_df['prev_prev_action'] == first_level]['prev_action'].unique():\n","        top_5 = third_level_df[(third_level_df['prev_prev_action'] == first_level) &\n","                               (third_level_df['prev_action'] == second_level)].nlargest(5, 'count')\n","        for _, row in top_5.iterrows():\n","            key = f\"{first_level}-{second_level}-{row['action']}\"\n","            third_level_actions[key] = {\n","                'count': int(row['count']),\n","                'level1_count': first_level_actions.get(first_level, 0),\n","                'level2_count': second_level_actions.get(f\"{first_level}-{second_level}\", {}).get('count', 0)\n","            }\n","third_level_actions = OrderedDict(sorted(third_level_actions.items(), key=lambda x: x[1]['count'], reverse=True))\n","\n","# Prepare the JSON output\n","result = {\n","    \"top_5_first_level_actions\": first_level_actions,\n","    \"top_5_second_level_actions_per_first\": second_level_actions,\n","    \"top_5_third_level_actions_per_combo\": third_level_actions\n","}\n","\n","# Function to remove NaN values and convert to int\n","def clean_dict(d):\n","    if isinstance(d, dict):\n","        return OrderedDict((str(k), clean_dict(v)) for k, v in d.items() if not (isinstance(v, float) and np.isnan(v)))\n","    elif isinstance(d, float) and not np.isnan(d):\n","        return int(d)\n","    else:\n","        return d\n","\n","# Clean the result dictionary\n","result = clean_dict(result)\n","\n","# Convert to JSON\n","json_output = json.dumps(result, indent=2)\n","\n","# Print the JSON output\n","print(json_output)\n","\n","# Optionally, save to a file\n","# with open('action_analysis.json', 'w') as f:\n","#     json.dump(result, f, indent=2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_vTyfrstbbpX","executionInfo":{"status":"ok","timestamp":1720158374846,"user_tz":240,"elapsed":289,"user":{"displayName":"Ram P","userId":"14475938172763703625"}},"outputId":"d3981950-fc80-4446-f1fb-09a9dc0eb55d"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["{\n","  \"top_5_first_level_actions\": {\n","    \"a12\": 7,\n","    \"a13\": 5,\n","    \"a14\": 4,\n","    \"a11\": 2,\n","    \"a15\": 1\n","  },\n","  \"top_5_second_level_actions_per_first\": {\n","    \"a12-a15\": {\n","      \"count\": 3,\n","      \"level1_count\": 7\n","    },\n","    \"a12-a13\": {\n","      \"count\": 2,\n","      \"level1_count\": 7\n","    },\n","    \"a13-a14\": {\n","      \"count\": 2,\n","      \"level1_count\": 5\n","    },\n","    \"a14-a11\": {\n","      \"count\": 2,\n","      \"level1_count\": 4\n","    },\n","    \"a14-a13\": {\n","      \"count\": 2,\n","      \"level1_count\": 4\n","    },\n","    \"a11-a13\": {\n","      \"count\": 1,\n","      \"level1_count\": 2\n","    },\n","    \"a11-a14\": {\n","      \"count\": 1,\n","      \"level1_count\": 2\n","    },\n","    \"a12-a11\": {\n","      \"count\": 1,\n","      \"level1_count\": 7\n","    },\n","    \"a12-a14\": {\n","      \"count\": 1,\n","      \"level1_count\": 7\n","    },\n","    \"a13-a11\": {\n","      \"count\": 1,\n","      \"level1_count\": 5\n","    },\n","    \"a13-a12\": {\n","      \"count\": 1,\n","      \"level1_count\": 5\n","    },\n","    \"a13-a15\": {\n","      \"count\": 1,\n","      \"level1_count\": 5\n","    },\n","    \"a15-a11\": {\n","      \"count\": 1,\n","      \"level1_count\": 1\n","    }\n","  },\n","  \"top_5_third_level_actions_per_combo\": {\n","    \"a12-a13-a11\": {\n","      \"count\": 2,\n","      \"level1_count\": 7,\n","      \"level2_count\": 2\n","    },\n","    \"a12-a15-a14\": {\n","      \"count\": 2,\n","      \"level1_count\": 7,\n","      \"level2_count\": 3\n","    },\n","    \"a13-a14-a11\": {\n","      \"count\": 2,\n","      \"level1_count\": 5,\n","      \"level2_count\": 2\n","    },\n","    \"a14-a11-a12\": {\n","      \"count\": 2,\n","      \"level1_count\": 4,\n","      \"level2_count\": 2\n","    },\n","    \"a14-a13-a15\": {\n","      \"count\": 2,\n","      \"level1_count\": 4,\n","      \"level2_count\": 2\n","    },\n","    \"a11-a13-a15\": {\n","      \"count\": 1,\n","      \"level1_count\": 2,\n","      \"level2_count\": 1\n","    },\n","    \"a11-a14-a13\": {\n","      \"count\": 1,\n","      \"level1_count\": 2,\n","      \"level2_count\": 1\n","    },\n","    \"a12-a11-a14\": {\n","      \"count\": 1,\n","      \"level1_count\": 7,\n","      \"level2_count\": 1\n","    },\n","    \"a12-a14-a15\": {\n","      \"count\": 1,\n","      \"level1_count\": 7,\n","      \"level2_count\": 1\n","    },\n","    \"a12-a15-a11\": {\n","      \"count\": 1,\n","      \"level1_count\": 7,\n","      \"level2_count\": 3\n","    },\n","    \"a13-a11-a12\": {\n","      \"count\": 1,\n","      \"level1_count\": 5,\n","      \"level2_count\": 1\n","    },\n","    \"a13-a12-a11\": {\n","      \"count\": 1,\n","      \"level1_count\": 5,\n","      \"level2_count\": 1\n","    },\n","    \"a13-a15-a14\": {\n","      \"count\": 1,\n","      \"level1_count\": 5,\n","      \"level2_count\": 1\n","    },\n","    \"a15-a11-a14\": {\n","      \"count\": 1,\n","      \"level1_count\": 1,\n","      \"level2_count\": 1\n","    }\n","  }\n","}\n"]}]}]}